<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Verify Face</title>
  <script defer src="./face-api.min.js"></script>
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background: #000;
      color: #0f0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      padding: 20px;
    }
    h2 { margin-bottom: 20px; }
    video {
      width: 100%;
      max-width: 640px;
      border-radius: 12px;
      border: 2px solid #0f0;
    }
    #result {
      margin-top: 20px;
      font-size: 1.5em;
      font-weight: bold;
    }
    #verifyBtn {
      margin-top: 15px;
      padding: 15px 40px;
      font-size: 1.2em;
      background: #0f0;
      color: #000;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      transition: transform 0.2s, background 0.2s;
    }
    #verifyBtn:hover {
      transform: scale(1.05);
      background: #0c0;
    }
    #log {
      margin-top: 20px;
      max-height: 200px;
      overflow: auto;
      background: #111;
      padding: 10px;
      width: 100%;
      max-width: 640px;
      white-space: pre-wrap;
      border-radius: 6px;
      border: 1px solid #0f0;
      font-size: 0.9em;
    }
  </style>
</head>
<body>
  <h2>Face Verification</h2>
  <video id="video" autoplay muted></video>
  <button id="verifyBtn">Verify Face</button>
  <div id="result">Waiting...</div>
  <div id="log"></div>

<script>
  const logEl = document.getElementById('log');
  const st = msg => document.getElementById('result').innerText = msg;
  function log(...args) { logEl.textContent += args.join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; }

  const MODELS_URI = './models';
  const image = localStorage.getItem("urrl") ;
  const REFERENCE_IMAGE = image;
  const THRESHOLD = 0.45;
  let referenceDescriptor = null;

  async function loadModels() {
    st('Loading models...');
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODELS_URI),
      faceapi.nets.faceLandmark68Net.loadFromUri(MODELS_URI),
      faceapi.nets.faceRecognitionNet.loadFromUri(MODELS_URI)
    ]);
    log('Models loaded');
  }

  async function startCamera() {
    const video = document.getElementById('video');
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
    return new Promise(resolve => video.onloadedmetadata = () => resolve(video));
  }

  async function loadReferenceImage() {
    const img = await faceapi.fetchImage(REFERENCE_IMAGE);
    const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks().withFaceDescriptor();
    if(!detection) throw new Error('No face found in reference image.');
    referenceDescriptor = detection.descriptor;
    log('Reference face loaded');
  }

  async function verifyFace() {
    st('Verifying...');
    const video = document.getElementById('video');
    const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks().withFaceDescriptor();
    if (!detection) {
      st('No face detected');
      log('No face detected');
      return;
    }
    const distance = faceapi.euclideanDistance(referenceDescriptor, detection.descriptor);
    log('Distance:', distance.toFixed(3));
    if(distance < THRESHOLD) {
      st('Verified ✅');
      localStorage.setItem('verified', 'true');
      setTimeout(() => window.location.href = 'index.html', 1000);
    } else {
      st('Not matching ❌');
    }
  }

  document.getElementById('verifyBtn').onclick = verifyFace;

  async function init() {
    try {
      await loadModels();
      await startCamera();
      await loadReferenceImage();
      st('Ready — click "Verify Face"');
    } catch(err) {
      st('Initialization error');
      log('Error:', err);
    }
  }

  window.addEventListener('load', init);
</script>
</body>
</html>
